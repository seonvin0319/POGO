# File: pogogo/run_comparison.py

#!/usr/bin/env python3
"""
POGO í†µí•© í•™ìŠµ ì‹¤í—˜ ëŸ°ì²˜ (ìˆœì°¨ ì‹¤í–‰ ë²„ì „)
- config.yamlì— ì •ì˜ëœ í™˜ê²½/í•˜ì´í¼ë¥¼ ìˆœì°¨ ìˆ˜í–‰ (ë³‘ë ¬ì²˜ë¦¬ ì—†ìŒ)
- í†µí•© í•™ìŠµ: actor_oneê³¼ actor_twoë¥¼ ë™ì‹œì— í•™ìŠµ
- TD targetì— online policy ì‚¬ìš©
- ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµ ê°€ëŠ¥ (load ëª¨ë“œ)
- GPU ì‚¬ìš©
"""

import os
import sys
import time
import json
import yaml
import subprocess
from pathlib import Path
from datetime import datetime
from argparse import ArgumentParser
from typing import Optional, List, Dict, Tuple

# ----------------------------
# ìœ í‹¸
# ----------------------------
def now_str():
    return datetime.now().strftime("%Y-%m-%d_%H:%M:%S")

def safe(s: str) -> str:
    return s.replace('/', '_').replace('-', '_')

def load_yaml(path: Path):
    with path.open('r') as f:
        return yaml.safe_load(f)

def write_json(path: Path, obj):
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2))

def tail(path: Path, n=50):
    if not path.exists():
        return ""
    with path.open('r', encoding='utf-8', errors='replace') as f:
        lines = f.readlines()
    return ''.join(lines[-n:])

def format_w2_weight(w: float) -> str:
    """w2 weightë¥¼ ì ì‘í˜•ìœ¼ë¡œ í¬ë§·íŒ… (í•„ìš”í•œ ì†Œìˆ˜ì  ìë¦¬ìˆ˜ë§Œ í‘œì‹œ)"""
    # ì •ìˆ˜ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if abs(w - round(w)) < 1e-10:
        return str(int(round(w)))
    
    # ì†Œìˆ˜ì ì´ ìˆëŠ” ê²½ìš°, ìµœëŒ€ 6ìë¦¬ê¹Œì§€ ì‹œë„í•˜ë©´ì„œ trailing zero ì œê±°
    # ê° precisionì—ì„œ í¬ë§·íŒ… í›„ ì›ë˜ ê°’ê³¼ ë¹„êµ
    for precision in range(1, 7):
        formatted = f"{w:.{precision}f}"
        # trailing zeroì™€ ì†Œìˆ˜ì  ì œê±°
        cleaned = formatted.rstrip('0').rstrip('.')
        # í¬ë§·íŒ…ëœ ê°’ì´ ì›ë˜ ê°’ê³¼ ê°™ìœ¼ë©´ ë°˜í™˜
        try:
            if abs(float(cleaned) - w) < 1e-10:
                return cleaned
        except ValueError:
            continue
    
    # ìœ„ ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ìµœëŒ€ precisionìœ¼ë¡œ í‘œì‹œ
    s = f"{w:.6f}".rstrip('0').rstrip('.')
    return s if s else "0"

# ----------------------------
# ì²´í¬ / ì‹¤í–‰ í•¨ìˆ˜ë“¤
# ----------------------------
def find_checkpoint(ckpt_dir: Path, step: Optional[int] = None) -> Optional[Path]:
    """ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°. stepì´ ì§€ì •ë˜ë©´ _mid_<step>_*_actor_0 íŒŒì¼ì„ ì°¾ìŒ."""
    if step is not None:
        # ì •í™• ë§¤ì¹˜
        for f in ckpt_dir.glob(f"*_mid_{step}_*_actor_0"):
            return f
        # ê·¼ì ‘ ë§¤ì¹˜
        best = None
        best_diff = 1e18
        for f in ckpt_dir.glob("*_mid_*_actor_0"):
            parts = f.stem.split('_')
            for i, p in enumerate(parts):
                if p == 'mid' and i + 1 < len(parts):
                    try:
                        t = int(parts[i + 1])
                    except Exception:
                        continue
                    diff = abs(t - step)
                    if diff < best_diff:
                        best_diff = diff
                        best = f
        return best
    else:
        # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸° (actor_0 ê¸°ì¤€)
        checkpoints = list(ckpt_dir.glob("*_actor_0"))
        if not checkpoints:
            return None
        return max(checkpoints, key=lambda p: p.stat().st_mtime)

def training_done(log_file: Path) -> bool:
    """í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ë¡œê·¸ë¡œ íŒì •(ìµœì¢… í‘œê¸° ë¬¸ìì—´ ê¸°ë°˜)."""
    if not log_file.exists():
        return False
    txt = log_file.read_text(errors='replace')
    return ('======== Final Evaluation' in txt
            and '[FINAL] Deterministic:' in txt
            and '[FINAL] Stochastic:' in txt)


def run_phase(
    pyexec: Path, root_dir: Path, args: List[str], log_path: Path, env: Optional[Dict] = None
) -> Tuple[int, Optional[str]]:
    """main.py í•œ ë²ˆ ì‹¤í–‰. rc, ì˜ˆì™¸ë©”ì‹œì§€ ë°˜í™˜.
    ì˜ˆì‹œ ì½”ë“œì²˜ëŸ¼ ë‹¨ìˆœí•˜ê²Œ íŒŒì¼ì— ì§ì ‘ ë¦¬ë‹¤ì´ë ‰íŠ¸í•©ë‹ˆë‹¤.
    """
    log_path.parent.mkdir(parents=True, exist_ok=True)
    rc, err = 0, None
    
    try:
        env_vars = (env or os.environ.copy())
        env_vars['PYTHONUNBUFFERED'] = '1'
        
        with log_path.open('w', encoding='utf-8') as logf:
            proc = subprocess.Popen(
                [str(pyexec), '-u', 'main.py'] + args,
                cwd=str(root_dir),
                env=env_vars,
                stdout=logf,
                stderr=subprocess.STDOUT,
                text=True
            )
            proc.wait()
            rc = proc.returncode
    except Exception as e:
        rc, err = -999, f"{type(e).__name__}: {e}"
    return rc, err

def strip_suffix(load_prefix: str) -> str:
    """..._actor_i / _critic ë“±ì˜ ì ‘ë¯¸ë¥¼ ì œê±°í•œ í”„ë¦¬í”½ìŠ¤ ë°˜í™˜."""
    suffixes = [
        '_actor_0', '_actor_1', '_actor_2',  # multi-actorìš©
        '_actor', '_critic', '_behavior',
        '_actor_optimizer', '_critic_optimizer', '_behavior_optimizer',
    ]
    for suf in suffixes:
        if load_prefix.endswith(suf):
            return load_prefix[:-len(suf)]
    return load_prefix

# ----------------------------
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ----------------------------
def run_unified_training(env_id: str, seed: int, w2_weights: List[float], 
                         lr: float, max_steps: int, eval_freq: int, split_ratio: float,
                         root_dir: Path, pyexec: Path) -> dict:
    """í†µí•© í•™ìŠµ ì‹¤í—˜: 0 â†’ max_steps (ëª¨ë“  actor ë™ì‹œ í•™ìŠµ)"""
    start = time.time()
    split_step = int(round(max_steps * split_ratio))
    
    # ë¡œê·¸/ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
    logs_root = Path('logs')
    w2_str = "_".join([format_w2_weight(w) for w in w2_weights])
    base = logs_root / safe(env_id) / f"w2_{w2_str}" / f"seed_{seed}"
    ckpt_dir = base / "checkpoints"
    log_dir = base / "training"
    log_dir.mkdir(parents=True, exist_ok=True)
    ckpt_dir.mkdir(parents=True, exist_ok=True)
    
    # ì™„ë£Œëœ ë¡œê·¸ í™•ì¸
    existing_logs = list(log_dir.glob("POGO_unifiedd*.log"))
    for log_file in existing_logs:
        if training_done(log_file):
            print(f"â­ï¸  í†µí•© í•™ìŠµ ìŠ¤í‚µ: {env_id} seed={seed} â€” ì´ë¯¸ ì™„ë£Œë¨ ({log_file.name})")
            return {
                'env': env_id, 'seed': seed, 'experiment_type': 'unified',
                'status': 'skipped_already_done', 'duration_min': 0.0,
                'log': str(log_file.resolve()), 'checkpoint_dir': str(ckpt_dir.resolve())
            }
    
    
    print(f"ğŸ”„ í†µí•© í•™ìŠµ ì‹œì‘: {env_id} seed={seed} â€” 0â†’{max_steps}")
    
    log_file = log_dir / f"POGO_unified_{safe(env_id)}_{seed}_{now_str().replace(':','-')}.log"
    
    env_vars = os.environ.copy()
    env_vars['CUDA_VISIBLE_DEVICES'] = '0'  # GPU ì‚¬ìš©
    
    args_list = [
        '--env', env_id,
        '--seed', str(seed),
        '--max_timesteps', str(max_steps),
        '--eval_freq', str(eval_freq),
        '--w2_weights'] + [str(w) for w in w2_weights] + [
        '--lr', str(lr),
        '--checkpoint_dir', str(ckpt_dir),
        '--save_model',
    ]
    
    rc, err = run_phase(
        pyexec, root_dir,
        args=args_list,
        log_path=log_file,
        env=env_vars
    )
    
    if rc != 0 or err:
        print(f"âŒ í†µí•© í•™ìŠµ ì‹¤íŒ¨: rc={rc}, err={err}\n{tail(log_file, 30)}")
        return {
            'env': env_id, 'seed': seed, 'experiment_type': 'unified',
            'status': 'failed', 'rc': rc, 'err': err, 'log': str(log_file.resolve())
        }
    
    dur_min = (time.time() - start) / 60.0
    return {
        'env': env_id, 'seed': seed, 'experiment_type': 'unified',
        'status': 'success', 'duration_min': round(dur_min, 3),
        'log': str(log_file.resolve()), 'checkpoint_dir': str(ckpt_dir.resolve())
    }


def main():
    ap = ArgumentParser()
    ap.add_argument('--config', default='config.yaml')
    ap.add_argument('--root_dir', default='.')
    ap.add_argument('--pyexec', default='/home/offrl/miniconda3/envs/offrl/bin/python')
    args = ap.parse_args()

    root_dir = Path(args.root_dir)
    pyexec = Path(args.pyexec)
    # config.yaml ê²½ë¡œ: í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ë¨¼ì € ì°¾ê³ , ì—†ìœ¼ë©´ root_dir ê¸°ì¤€ìœ¼ë¡œ ì°¾ê¸°
    config_path = Path(args.config)
    if not config_path.is_absolute():
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš°, í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ë¨¼ì € ì°¾ê¸°
        if config_path.exists():
            config_path = config_path.resolve()
        elif (root_dir / config_path).exists():
            config_path = root_dir / config_path
        elif (root_dir.parent / config_path).exists():
            config_path = root_dir.parent / config_path
        else:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
            config_path = Path.cwd() / config_path
    cfg = load_yaml(config_path)

    common = cfg['common']
    max_steps  = common['max_timesteps']
    eval_freq  = common['eval_freq']
    seeds      = common['seeds']
    split_ratio= common.get('split_ratio', 0.5)

    # í™˜ê²½ ìˆœì„œ ì •ì˜: halfcheetah â†’ hopper â†’ walker2d â†’ antmaze
    env_order = {
        'halfcheetah': ['medium', 'medium-replay', 'medium-expert'],
        'hopper': ['medium', 'medium-replay', 'medium-expert'], 
        'walker2d': ['medium', 'medium-replay', 'medium-expert'], 
        'antmaze': ['umaze-v2', 'umaze-diverse-v2', 'medium-play-v2', 'medium-diverse-v2', 'large-play-v2', 'large-diverse-v2'], 
    }

    all_runs = []
    for env_key in env_order.keys():
        if env_key not in cfg['environments']:
            continue
        datasets = cfg['environments'][env_key]
        for dataset_key in env_order[env_key]:
            if dataset_key not in datasets:
                continue
            env_cfg = datasets[dataset_key]
            env_id = f"{env_key}-{dataset_key}"
            
            all_runs.append({
                'env_id': env_id,
                'w2_weights': env_cfg['w2_weights'],
                'lr': env_cfg['learning_rate'],
            })

    print(f"ğŸ”¬ ì´ {len(all_runs)*len(seeds)}ê°œ ì‹¤í—˜ ì˜ˆì • (í†µí•© í•™ìŠµ)")
    print(f"ğŸ“‹ ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ")
    print(f"ğŸ”„ í†µí•© í•™ìŠµ: GPU ì‚¬ìš© (online policy for TD target)")
    
    results = []
    t0 = time.time()

    for seed in seeds:
        print(f"\nğŸ² SEED {seed} ì‹œì‘")
        for e in all_runs:
            w2_str = ", ".join([format_w2_weight(w) for w in e['w2_weights']])
            print(f"â€” {e['env_id']} | w2_weights=[{w2_str}] lr={e['lr']}")
            
            # í†µí•© í•™ìŠµ ì‹¤í–‰
            print(f"  ğŸ”„ í†µí•© í•™ìŠµ ì‹¤í–‰ ì¤‘...")
            r = run_unified_training(
                env_id=e['env_id'], seed=seed,
                w2_weights=e['w2_weights'],
                lr=e['lr'],
                max_steps=max_steps, eval_freq=eval_freq,
                split_ratio=split_ratio,
                root_dir=root_dir, pyexec=pyexec
            )
            results.append(r)
            print(f"  âœ… í†µí•© í•™ìŠµ ì™„ë£Œ: {r['status']}")
            
            print(f"âœ… {e['env_id']} seed={seed} ì™„ë£Œ")

    # ê²°ê³¼ ì €ì¥
    ts = now_str().replace(':','-')
    out_dir = Path(f"results_{ts}")
    out_dir.mkdir(exist_ok=True)
    
    # JSON ì €ì¥
    write_json(out_dir / "unified_summary.json", results)

    # CSV ì €ì¥
    csv_file = out_dir / "unified_results.csv"
    with csv_file.open('w', encoding='utf-8') as f:
        f.write("env,seed,experiment_type,status,rc,err,duration_min,log,checkpoint_dir\n")
        for r in results:
            f.write(f"{r.get('env','')},{r.get('seed','')},{r.get('experiment_type','')},"
                    f"{r.get('status','')},{r.get('rc','')},{r.get('err','')},"
                    f"{r.get('duration_min','')},{r.get('log','')},{r.get('checkpoint_dir','')}\n")

    mins = (time.time() - t0) / 60.0
    print("\nğŸ ì™„ë£Œ | ì´ ì†Œìš” {:.1f}ë¶„ | ê²°ê³¼: {}".format(mins, out_dir))
    print(f"ğŸ“Š í†µí•© í•™ìŠµ ê²°ê³¼: {csv_file}")

if __name__ == "__main__":
    main()

